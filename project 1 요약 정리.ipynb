{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 : 환율 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DATA SET은 2018년1월부터 2020년 1월까지.(총 2년 1개월)\n",
    "- SET01 ~ SET12는 DATA SET을 TRAIN SET 1년, TEST SET 1개월로 나누고 한달 간격으로 총 12개의 SET을 만듬(SLIDING WINDOW 방식)\n",
    "- prophet과 arima는 고시 환율만을 사용하여 모델을 구성하였으며, dnn은 환율, 미국과 한국의 3개월 리보금리, kospi300, s&p500 활용\n",
    "- 1,2,3번 전부 각각의 set을 통해 예측한 확률의 평균을 구성하였으며, 3번의 마지막 표만 1년을 예측하여 11개월을 평가한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. facebook prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 페이스북에서 개발한 시계열 예측 알고리즘이다. ARIMA 모델처럼 이론적으로 구성된 모형이 아니라 지금까지의 추세를 활용하므로 단기 시계열 예측에 좋은 성능으로 알려져 있다. prophet모델을 통해 장기적인 예측은 할 수 없지만, 단기에 환율의 방향을 예측할 수 있다. \n",
    "\n",
    "- prophet 모델을 이용하여  5일간의 환율 예측치를 예측한 결과 RMSE가 큰 차이를 보였으며, 또한 실제가격과 예측가격의 상승,하락만을 비교하였을때의 정확도는 약 42%정도로 환율 예측에 사용할 수 없는 모델로 생각된다. 이를 보완하기 위해 ARIMA모델을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < 코드 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from fbprophet import Prophet\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    data=pd.read_csv('data/USD_KRW.csv')\n",
    "    data.columns=['ds','y_original']\n",
    "    data=data.set_index('ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. data set 시작, 끝 날짜 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    start_date_train = ['2018-02-01','2018-03-01','2018-04-01','2018-05-01','2018-06-01','2018-07-01','2018-08-01','2018-09-01',\n",
    "                        '2018-10-01','2018-11-01','2018-12-01','2019-01-01']\n",
    "    end_date_train = ['2019-01-31','2019-02-28','2019-03-31','2019-04-30','2019-05-31','2019-06-30','2019-07-31','2019-08-31',\n",
    "                      '2019-09-30','2019-10-31','2019-11-30','2019-12-31']\n",
    "    start_date_test = ['2019-02-01','2019-03-01','2019-04-01','2019-05-01','2019-06-01','2019-07-01','2019-08-01','2019-09-01',\n",
    "                       '2019-10-01','2019-11-01','2019-12-01','2020-01-01']\n",
    "    end_date_test = ['2019-02-28','2019-03-31','2019-04-30','2019-05-31','2019-06-30','2019-07-31','2019-08-31','2019-09-30',\n",
    "                     '2019-10-31','2019-11-30','2019-12-31','2020-01-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. holiday 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    holiday_list = [\n",
    "           #2018 휴일\n",
    "           '2018-01-01','2018-01-06','2018-01-07','2018-01-13','2018-01-14','2018-01-20','2018-01-21','2018-01-27',\n",
    "           '2018-01-28','2018-02-03','2018-02-04','2018-02-10','2018-02-11','2018-02-15','2018-02-16','2018-02-17',\n",
    "           '2018-02-18','2018-02-24','2018-02-25','2018-03-01','2018-03-03','2018-03-04','2018-03-10','2018-03-11',\n",
    "           '2018-03-17','2018-03-18','2018-03-24','2018-03-25','2018-03-31','2018-04-01','2018-04-07','2018-04-08',\n",
    "           '2018-04-14','2018-04-15','2018-04-21','2018-04-22','2018-04-28','2018-04-29','2018-05-05','2018-05-06',\n",
    "           '2018-05-07','2018-05-12','2018-05-13','2018-05-19','2018-05-20','2018-05-22','2018-05-26','2018-05-27',\n",
    "           '2018-06-02','2018-06-03','2018-06-06','2018-06-09','2018-06-10','2018-06-13','2018-06-16','2018-06-17',\n",
    "           '2018-06-23','2018-06-24','2018-06-30','2018-07-01','2018-07-07','2018-07-08','2018-07-14','2018-07-15',\n",
    "           '2018-07-21','2018-07-22','2018-07-28','2018-07-29','2018-08-04','2018-08-05','2018-08-12','2018-08-15',\n",
    "           '2018-08-18','2018-08-19','2018-08-25','2018-08-26','2018-09-01','2018-09-02','2018-09-08','2018-09-09',\n",
    "           '2018-09-15','2018-09-16','2018-09-22','2018-09-23','2018-09-24','2018-09-25','2018-09-29','2018-09-30',\n",
    "           '2018-10-03','2018-10-06','2018-10-07','2018-10-09','2018-10-13','2018-10-14','2018-10-20','2018-10-21',\n",
    "           '2018-10-27','2018-10-28','2018-11-03','2018-11-04','2018-11-10','2018-11-11','2018-11-17','2018-11-18',\n",
    "           '2018-11-24','2018-11-25','2018-12-01','2018-12-02','2018-12-08','2018-12-09','2018-12-15','2018-12-16',\n",
    "           '2018-12-22','2018-12-23','2018-12-25','2018-12-29','2018-12-30',\n",
    "           #2019 휴일\n",
    "           '2019-01-01','2019-01-05','2019-01-06','2019-01-12','2019-01-13','2019-01-19','2019-01-20','2019-01-26',\n",
    "           '2019-01-27','2019-02-02','2019-02-03','2019-02-04','2019-02-05','2019-02-06','2019-02-09','2019-02-10',\n",
    "           '2019-02-16','2019-02-17','2019-02-23','2019-02-24','2019-03-01','2019-03-02','2019-03-03','2019-03-09',\n",
    "           '2019-03-10','2019-03-16','2019-03-17','2019-03-23','2019-03-24','2019-03-30','2019-03-31','2019-04-06',\n",
    "           '2019-04-07','2019-04-13','2019-04-14','2019-04-20','2019-04-21','2019-04-27','2019-04-28','2019-05-04',\n",
    "           '2019-05-05','2019-05-06','2019-05-11','2019-05-12','2019-05-18','2019-05-19','2019-05-25','2019-05-26',\n",
    "           '2019-06-01','2019-06-02','2019-06-06','2019-06-08','2019-06-09','2019-06-15','2019-06-16','2019-06-22',\n",
    "           '2019-06-23','2019-06-29','2019-06-30','2019-07-06','2019-07-07','2019-07-13','2019-07-14','2019-07-20',\n",
    "           '2019-07-21','2019-07-27','2019-07-28','2019-08-03','2019-08-04','2019-08-10','2019-08-11','2019-08-15',\n",
    "           '2019-08-17','2019-08-18','2019-08-24','2019-08-25','2019-08-31','2019-09-01','2019-09-07','2019-09-08',\n",
    "           '2019-09-12','2019-09-13','2019-09-14','2019-09-15','2019-09-21','2019-09-22','2019-09-28','2019-09-29',\n",
    "           '2019-10-03','2019-10-05','2019-10-06','2019-10-09','2019-10-12','2019-10-13','2019-10-19','2019-10-20',\n",
    "           '2019-10-26','2019-10-27','2019-11-02','2019-11-03','2019-11-09','2019-11-10','2019-11-16','2019-11-17',\n",
    "           '2019-11-23','2019-11-24','2019-11-30','2019-12-01','2019-12-07','2019-12-08','2019-12-14','2019-12-15',\n",
    "           '2019-12-21','2019-12-22','2019-12-25','2019-12-28','2019-12-29',\n",
    "           #2020 휴일\n",
    "           '2020-01-01','2020-01-04','2020-01-05','2020-01-11','2020-01-12','2020-01-18','2020-01-19','2020-01-24',\n",
    "           '2020-01-25','2020-01-26','2020-01-27']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. train, test set 나누기위해 holiday 구분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    trh1 = ['2018-02-03','2018-02-04','2018-02-10','2018-02-11','2018-02-15','2018-02-16','2018-02-17',\n",
    "           '2018-02-18','2018-02-24','2018-02-25','2018-03-01','2018-03-03','2018-03-04','2018-03-10','2018-03-11',\n",
    "           '2018-03-17','2018-03-18','2018-03-24','2018-03-25','2018-03-31','2018-04-01','2018-04-07','2018-04-08',\n",
    "           '2018-04-14','2018-04-15','2018-04-21','2018-04-22','2018-04-28','2018-04-29','2018-05-05','2018-05-06',\n",
    "           '2018-05-07','2018-05-12','2018-05-13','2018-05-19','2018-05-20','2018-05-22','2018-05-26','2018-05-27',\n",
    "           '2018-06-02','2018-06-03','2018-06-06','2018-06-09','2018-06-10','2018-06-13','2018-06-16','2018-06-17',\n",
    "           '2018-06-23','2018-06-24','2018-06-30','2018-07-01','2018-07-07','2018-07-08','2018-07-14','2018-07-15',\n",
    "           '2018-07-21','2018-07-22','2018-07-28','2018-07-29','2018-08-04','2018-08-05','2018-08-12','2018-08-15',\n",
    "           '2018-08-18','2018-08-19','2018-08-25','2018-08-26','2018-09-01','2018-09-02','2018-09-08','2018-09-09',\n",
    "           '2018-09-15','2018-09-16','2018-09-22','2018-09-23','2018-09-24','2018-09-25','2018-09-29','2018-09-30',\n",
    "           '2018-10-03','2018-10-06','2018-10-07','2018-10-09','2018-10-13','2018-10-14','2018-10-20','2018-10-21',\n",
    "           '2018-10-27','2018-10-28','2018-11-03','2018-11-04','2018-11-10','2018-11-11','2018-11-17','2018-11-18',\n",
    "           '2018-11-24','2018-11-25','2018-12-01','2018-12-02','2018-12-08','2018-12-09','2018-12-15','2018-12-16',\n",
    "           '2018-12-22','2018-12-23','2018-12-25','2018-12-29','2018-12-30','2019-01-01','2019-01-05','2019-01-06',\n",
    "           '2019-01-12','2019-01-13','2019-01-19','2019-01-20','2019-01-26','2019-01-27']\n",
    "    trh2 = ['2018-03-01','2018-03-03','2018-03-04','2018-03-10','2018-03-11',\n",
    "           '2018-03-17','2018-03-18','2018-03-24','2018-03-25','2018-03-31','2018-04-01','2018-04-07','2018-04-08',\n",
    "           '2018-04-14','2018-04-15','2018-04-21','2018-04-22','2018-04-28','2018-04-29','2018-05-05','2018-05-06',\n",
    "           '2018-05-07','2018-05-12','2018-05-13','2018-05-19','2018-05-20','2018-05-22','2018-05-26','2018-05-27',\n",
    "           '2018-06-02','2018-06-03','2018-06-06','2018-06-09','2018-06-10','2018-06-13','2018-06-16','2018-06-17',\n",
    "           '2018-06-23','2018-06-24','2018-06-30','2018-07-01','2018-07-07','2018-07-08','2018-07-14','2018-07-15',\n",
    "           '2018-07-21','2018-07-22','2018-07-28','2018-07-29','2018-08-04','2018-08-05','2018-08-12','2018-08-15',\n",
    "           '2018-08-18','2018-08-19','2018-08-25','2018-08-26','2018-09-01','2018-09-02','2018-09-08','2018-09-09',\n",
    "           '2018-09-15','2018-09-16','2018-09-22','2018-09-23','2018-09-24','2018-09-25','2018-09-29','2018-09-30',\n",
    "           '2018-10-03','2018-10-06','2018-10-07','2018-10-09','2018-10-13','2018-10-14','2018-10-20','2018-10-21',\n",
    "           '2018-10-27','2018-10-28','2018-11-03','2018-11-04','2018-11-10','2018-11-11','2018-11-17','2018-11-18',\n",
    "           '2018-11-24','2018-11-25','2018-12-01','2018-12-02','2018-12-08','2018-12-09','2018-12-15','2018-12-16',\n",
    "           '2018-12-22','2018-12-23','2018-12-25','2018-12-29','2018-12-30',\n",
    "           '2019-01-01','2019-01-05','2019-01-06','2019-01-12','2019-01-13','2019-01-19','2019-01-20','2019-01-26',\n",
    "           '2019-01-27','2019-02-02','2019-02-03','2019-02-04','2019-02-05','2019-02-06','2019-02-09','2019-02-10',\n",
    "           '2019-02-16','2019-02-17','2019-02-23','2019-02-24']\n",
    "    trh3 = ['2018-04-01','2018-04-07','2018-04-08',\n",
    "           '2018-04-14','2018-04-15','2018-04-21','2018-04-22','2018-04-28','2018-04-29','2018-05-05','2018-05-06',\n",
    "           '2018-05-07','2018-05-12','2018-05-13','2018-05-19','2018-05-20','2018-05-22','2018-05-26','2018-05-27',\n",
    "           '2018-06-02','2018-06-03','2018-06-06','2018-06-09','2018-06-10','2018-06-13','2018-06-16','2018-06-17',\n",
    "           '2018-06-23','2018-06-24','2018-06-30','2018-07-01','2018-07-07','2018-07-08','2018-07-14','2018-07-15',\n",
    "           '2018-07-21','2018-07-22','2018-07-28','2018-07-29','2018-08-04','2018-08-05','2018-08-12','2018-08-15',\n",
    "           '2018-08-18','2018-08-19','2018-08-25','2018-08-26','2018-09-01','2018-09-02','2018-09-08','2018-09-09',\n",
    "           '2018-09-15','2018-09-16','2018-09-22','2018-09-23','2018-09-24','2018-09-25','2018-09-29','2018-09-30',\n",
    "           '2018-10-03','2018-10-06','2018-10-07','2018-10-09','2018-10-13','2018-10-14','2018-10-20','2018-10-21',\n",
    "           '2018-10-27','2018-10-28','2018-11-03','2018-11-04','2018-11-10','2018-11-11','2018-11-17','2018-11-18',\n",
    "           '2018-11-24','2018-11-25','2018-12-01','2018-12-02','2018-12-08','2018-12-09','2018-12-15','2018-12-16',\n",
    "           '2018-12-22','2018-12-23','2018-12-25','2018-12-29','2018-12-30',\n",
    "           '2019-01-01','2019-01-05','2019-01-06','2019-01-12','2019-01-13','2019-01-19','2019-01-20','2019-01-26',\n",
    "           '2019-01-27','2019-02-02','2019-02-03','2019-02-04','2019-02-05','2019-02-06','2019-02-09','2019-02-10',\n",
    "           '2019-02-16','2019-02-17','2019-02-23','2019-02-24','2019-03-01','2019-03-02','2019-03-03','2019-03-09',\n",
    "           '2019-03-10','2019-03-16','2019-03-17','2019-03-23','2019-03-24','2019-03-30','2019-03-31'] \n",
    "    trh4 = ['2018-05-05','2018-05-06',\n",
    "           '2018-05-07','2018-05-12','2018-05-13','2018-05-19','2018-05-20','2018-05-22','2018-05-26','2018-05-27',\n",
    "           '2018-06-02','2018-06-03','2018-06-06','2018-06-09','2018-06-10','2018-06-13','2018-06-16','2018-06-17',\n",
    "           '2018-06-23','2018-06-24','2018-06-30','2018-07-01','2018-07-07','2018-07-08','2018-07-14','2018-07-15',\n",
    "           '2018-07-21','2018-07-22','2018-07-28','2018-07-29','2018-08-04','2018-08-05','2018-08-12','2018-08-15',\n",
    "           '2018-08-18','2018-08-19','2018-08-25','2018-08-26','2018-09-01','2018-09-02','2018-09-08','2018-09-09',\n",
    "           '2018-09-15','2018-09-16','2018-09-22','2018-09-23','2018-09-24','2018-09-25','2018-09-29','2018-09-30',\n",
    "           '2018-10-03','2018-10-06','2018-10-07','2018-10-09','2018-10-13','2018-10-14','2018-10-20','2018-10-21',\n",
    "           '2018-10-27','2018-10-28','2018-11-03','2018-11-04','2018-11-10','2018-11-11','2018-11-17','2018-11-18',\n",
    "           '2018-11-24','2018-11-25','2018-12-01','2018-12-02','2018-12-08','2018-12-09','2018-12-15','2018-12-16',\n",
    "           '2018-12-22','2018-12-23','2018-12-25','2018-12-29','2018-12-30',\n",
    "           '2019-01-01','2019-01-05','2019-01-06','2019-01-12','2019-01-13','2019-01-19','2019-01-20','2019-01-26',\n",
    "           '2019-01-27','2019-02-02','2019-02-03','2019-02-04','2019-02-05','2019-02-06','2019-02-09','2019-02-10',\n",
    "           '2019-02-16','2019-02-17','2019-02-23','2019-02-24','2019-03-01','2019-03-02','2019-03-03','2019-03-09',\n",
    "           '2019-03-10','2019-03-16','2019-03-17','2019-03-23','2019-03-24','2019-03-30','2019-03-31','2019-04-06',\n",
    "           '2019-04-07','2019-04-13','2019-04-14','2019-04-20','2019-04-21','2019-04-27','2019-04-28']\n",
    "    trh5 = ['2018-06-02','2018-06-03','2018-06-06','2018-06-09','2018-06-10','2018-06-13','2018-06-16','2018-06-17',\n",
    "           '2018-06-23','2018-06-24','2018-06-30','2018-07-01','2018-07-07','2018-07-08','2018-07-14','2018-07-15',\n",
    "           '2018-07-21','2018-07-22','2018-07-28','2018-07-29','2018-08-04','2018-08-05','2018-08-12','2018-08-15',\n",
    "           '2018-08-18','2018-08-19','2018-08-25','2018-08-26','2018-09-01','2018-09-02','2018-09-08','2018-09-09',\n",
    "           '2018-09-15','2018-09-16','2018-09-22','2018-09-23','2018-09-24','2018-09-25','2018-09-29','2018-09-30',\n",
    "           '2018-10-03','2018-10-06','2018-10-07','2018-10-09','2018-10-13','2018-10-14','2018-10-20','2018-10-21',\n",
    "           '2018-10-27','2018-10-28','2018-11-03','2018-11-04','2018-11-10','2018-11-11','2018-11-17','2018-11-18',\n",
    "           '2018-11-24','2018-11-25','2018-12-01','2018-12-02','2018-12-08','2018-12-09','2018-12-15','2018-12-16',\n",
    "           '2018-12-22','2018-12-23','2018-12-25','2018-12-29','2018-12-30',\n",
    "           '2019-01-01','2019-01-05','2019-01-06','2019-01-12','2019-01-13','2019-01-19','2019-01-20','2019-01-26',\n",
    "           '2019-01-27','2019-02-02','2019-02-03','2019-02-04','2019-02-05','2019-02-06','2019-02-09','2019-02-10',\n",
    "           '2019-02-16','2019-02-17','2019-02-23','2019-02-24','2019-03-01','2019-03-02','2019-03-03','2019-03-09',\n",
    "           '2019-03-10','2019-03-16','2019-03-17','2019-03-23','2019-03-24','2019-03-30','2019-03-31','2019-04-06',\n",
    "           '2019-04-07','2019-04-13','2019-04-14','2019-04-20','2019-04-21','2019-04-27','2019-04-28','2019-05-04',\n",
    "           '2019-05-05','2019-05-06','2019-05-11','2019-05-12','2019-05-18','2019-05-19','2019-05-25','2019-05-26'] \n",
    "    trh6 = ['2018-07-01','2018-07-07','2018-07-08','2018-07-14','2018-07-15',\n",
    "           '2018-07-21','2018-07-22','2018-07-28','2018-07-29','2018-08-04','2018-08-05','2018-08-12','2018-08-15',\n",
    "           '2018-08-18','2018-08-19','2018-08-25','2018-08-26','2018-09-01','2018-09-02','2018-09-08','2018-09-09',\n",
    "           '2018-09-15','2018-09-16','2018-09-22','2018-09-23','2018-09-24','2018-09-25','2018-09-29','2018-09-30',\n",
    "           '2018-10-03','2018-10-06','2018-10-07','2018-10-09','2018-10-13','2018-10-14','2018-10-20','2018-10-21',\n",
    "           '2018-10-27','2018-10-28','2018-11-03','2018-11-04','2018-11-10','2018-11-11','2018-11-17','2018-11-18',\n",
    "           '2018-11-24','2018-11-25','2018-12-01','2018-12-02','2018-12-08','2018-12-09','2018-12-15','2018-12-16',\n",
    "           '2018-12-22','2018-12-23','2018-12-25','2018-12-29','2018-12-30',\n",
    "           '2019-01-01','2019-01-05','2019-01-06','2019-01-12','2019-01-13','2019-01-19','2019-01-20','2019-01-26',\n",
    "           '2019-01-27','2019-02-02','2019-02-03','2019-02-04','2019-02-05','2019-02-06','2019-02-09','2019-02-10',\n",
    "           '2019-02-16','2019-02-17','2019-02-23','2019-02-24','2019-03-01','2019-03-02','2019-03-03','2019-03-09',\n",
    "           '2019-03-10','2019-03-16','2019-03-17','2019-03-23','2019-03-24','2019-03-30','2019-03-31','2019-04-06',\n",
    "           '2019-04-07','2019-04-13','2019-04-14','2019-04-20','2019-04-21','2019-04-27','2019-04-28','2019-05-04',\n",
    "           '2019-05-05','2019-05-06','2019-05-11','2019-05-12','2019-05-18','2019-05-19','2019-05-25','2019-05-26',\n",
    "           '2019-06-01','2019-06-02','2019-06-06','2019-06-08','2019-06-09','2019-06-15','2019-06-16','2019-06-22',\n",
    "           '2019-06-23','2019-06-29','2019-06-30']\n",
    "    trh7 = ['2018-08-04','2018-08-05','2018-08-12','2018-08-15',\n",
    "           '2018-08-18','2018-08-19','2018-08-25','2018-08-26','2018-09-01','2018-09-02','2018-09-08','2018-09-09',\n",
    "           '2018-09-15','2018-09-16','2018-09-22','2018-09-23','2018-09-24','2018-09-25','2018-09-29','2018-09-30',\n",
    "           '2018-10-03','2018-10-06','2018-10-07','2018-10-09','2018-10-13','2018-10-14','2018-10-20','2018-10-21',\n",
    "           '2018-10-27','2018-10-28','2018-11-03','2018-11-04','2018-11-10','2018-11-11','2018-11-17','2018-11-18',\n",
    "           '2018-11-24','2018-11-25','2018-12-01','2018-12-02','2018-12-08','2018-12-09','2018-12-15','2018-12-16',\n",
    "           '2018-12-22','2018-12-23','2018-12-25','2018-12-29','2018-12-30',\n",
    "           '2019-01-01','2019-01-05','2019-01-06','2019-01-12','2019-01-13','2019-01-19','2019-01-20','2019-01-26',\n",
    "           '2019-01-27','2019-02-02','2019-02-03','2019-02-04','2019-02-05','2019-02-06','2019-02-09','2019-02-10',\n",
    "           '2019-02-16','2019-02-17','2019-02-23','2019-02-24','2019-03-01','2019-03-02','2019-03-03','2019-03-09',\n",
    "           '2019-03-10','2019-03-16','2019-03-17','2019-03-23','2019-03-24','2019-03-30','2019-03-31','2019-04-06',\n",
    "           '2019-04-07','2019-04-13','2019-04-14','2019-04-20','2019-04-21','2019-04-27','2019-04-28','2019-05-04',\n",
    "           '2019-05-05','2019-05-06','2019-05-11','2019-05-12','2019-05-18','2019-05-19','2019-05-25','2019-05-26',\n",
    "           '2019-06-01','2019-06-02','2019-06-06','2019-06-08','2019-06-09','2019-06-15','2019-06-16','2019-06-22',\n",
    "           '2019-06-23','2019-06-29','2019-06-30','2019-07-06','2019-07-07','2019-07-13','2019-07-14','2019-07-20',\n",
    "           '2019-07-21','2019-07-27','2019-07-28']\n",
    "    trh8 = ['2018-09-01','2018-09-02','2018-09-08','2018-09-09',\n",
    "           '2018-09-15','2018-09-16','2018-09-22','2018-09-23','2018-09-24','2018-09-25','2018-09-29','2018-09-30',\n",
    "           '2018-10-03','2018-10-06','2018-10-07','2018-10-09','2018-10-13','2018-10-14','2018-10-20','2018-10-21',\n",
    "           '2018-10-27','2018-10-28','2018-11-03','2018-11-04','2018-11-10','2018-11-11','2018-11-17','2018-11-18',\n",
    "           '2018-11-24','2018-11-25','2018-12-01','2018-12-02','2018-12-08','2018-12-09','2018-12-15','2018-12-16',\n",
    "           '2018-12-22','2018-12-23','2018-12-25','2018-12-29','2018-12-30',\n",
    "           '2019-01-01','2019-01-05','2019-01-06','2019-01-12','2019-01-13','2019-01-19','2019-01-20','2019-01-26',\n",
    "           '2019-01-27','2019-02-02','2019-02-03','2019-02-04','2019-02-05','2019-02-06','2019-02-09','2019-02-10',\n",
    "           '2019-02-16','2019-02-17','2019-02-23','2019-02-24','2019-03-01','2019-03-02','2019-03-03','2019-03-09',\n",
    "           '2019-03-10','2019-03-16','2019-03-17','2019-03-23','2019-03-24','2019-03-30','2019-03-31','2019-04-06',\n",
    "           '2019-04-07','2019-04-13','2019-04-14','2019-04-20','2019-04-21','2019-04-27','2019-04-28','2019-05-04',\n",
    "           '2019-05-05','2019-05-06','2019-05-11','2019-05-12','2019-05-18','2019-05-19','2019-05-25','2019-05-26',\n",
    "           '2019-06-01','2019-06-02','2019-06-06','2019-06-08','2019-06-09','2019-06-15','2019-06-16','2019-06-22',\n",
    "           '2019-06-23','2019-06-29','2019-06-30','2019-07-06','2019-07-07','2019-07-13','2019-07-14','2019-07-20',\n",
    "           '2019-07-21','2019-07-27','2019-07-28','2019-08-03','2019-08-04','2019-08-10','2019-08-11','2019-08-15',\n",
    "           '2019-08-17','2019-08-18','2019-08-24','2019-08-25','2019-08-31']\n",
    "    trh9 = ['2018-10-03','2018-10-06','2018-10-07','2018-10-09','2018-10-13','2018-10-14','2018-10-20','2018-10-21',\n",
    "           '2018-10-27','2018-10-28','2018-11-03','2018-11-04','2018-11-10','2018-11-11','2018-11-17','2018-11-18',\n",
    "           '2018-11-24','2018-11-25','2018-12-01','2018-12-02','2018-12-08','2018-12-09','2018-12-15','2018-12-16',\n",
    "           '2018-12-22','2018-12-23','2018-12-25','2018-12-29','2018-12-30',\n",
    "           '2019-01-01','2019-01-05','2019-01-06','2019-01-12','2019-01-13','2019-01-19','2019-01-20','2019-01-26',\n",
    "           '2019-01-27','2019-02-02','2019-02-03','2019-02-04','2019-02-05','2019-02-06','2019-02-09','2019-02-10',\n",
    "           '2019-02-16','2019-02-17','2019-02-23','2019-02-24','2019-03-01','2019-03-02','2019-03-03','2019-03-09',\n",
    "           '2019-03-10','2019-03-16','2019-03-17','2019-03-23','2019-03-24','2019-03-30','2019-03-31','2019-04-06',\n",
    "           '2019-04-07','2019-04-13','2019-04-14','2019-04-20','2019-04-21','2019-04-27','2019-04-28','2019-05-04',\n",
    "           '2019-05-05','2019-05-06','2019-05-11','2019-05-12','2019-05-18','2019-05-19','2019-05-25','2019-05-26',\n",
    "           '2019-06-01','2019-06-02','2019-06-06','2019-06-08','2019-06-09','2019-06-15','2019-06-16','2019-06-22',\n",
    "           '2019-06-23','2019-06-29','2019-06-30','2019-07-06','2019-07-07','2019-07-13','2019-07-14','2019-07-20',\n",
    "           '2019-07-21','2019-07-27','2019-07-28','2019-08-03','2019-08-04','2019-08-10','2019-08-11','2019-08-15',\n",
    "           '2019-08-17','2019-08-18','2019-08-24','2019-08-25','2019-08-31','2019-09-01','2019-09-07','2019-09-08',\n",
    "           '2019-09-12','2019-09-13','2019-09-14','2019-09-15','2019-09-21','2019-09-22','2019-09-28','2019-09-29']\n",
    "    trh10 = ['2018-11-03','2018-11-04','2018-11-10','2018-11-11','2018-11-17','2018-11-18',\n",
    "           '2018-11-24','2018-11-25','2018-12-01','2018-12-02','2018-12-08','2018-12-09','2018-12-15','2018-12-16',\n",
    "           '2018-12-22','2018-12-23','2018-12-25','2018-12-29','2018-12-30',\n",
    "           '2019-01-01','2019-01-05','2019-01-06','2019-01-12','2019-01-13','2019-01-19','2019-01-20','2019-01-26',\n",
    "           '2019-01-27','2019-02-02','2019-02-03','2019-02-04','2019-02-05','2019-02-06','2019-02-09','2019-02-10',\n",
    "           '2019-02-16','2019-02-17','2019-02-23','2019-02-24','2019-03-01','2019-03-02','2019-03-03','2019-03-09',\n",
    "           '2019-03-10','2019-03-16','2019-03-17','2019-03-23','2019-03-24','2019-03-30','2019-03-31','2019-04-06',\n",
    "           '2019-04-07','2019-04-13','2019-04-14','2019-04-20','2019-04-21','2019-04-27','2019-04-28','2019-05-04',\n",
    "           '2019-05-05','2019-05-06','2019-05-11','2019-05-12','2019-05-18','2019-05-19','2019-05-25','2019-05-26',\n",
    "           '2019-06-01','2019-06-02','2019-06-06','2019-06-08','2019-06-09','2019-06-15','2019-06-16','2019-06-22',\n",
    "           '2019-06-23','2019-06-29','2019-06-30','2019-07-06','2019-07-07','2019-07-13','2019-07-14','2019-07-20',\n",
    "           '2019-07-21','2019-07-27','2019-07-28','2019-08-03','2019-08-04','2019-08-10','2019-08-11','2019-08-15',\n",
    "           '2019-08-17','2019-08-18','2019-08-24','2019-08-25','2019-08-31','2019-09-01','2019-09-07','2019-09-08',\n",
    "           '2019-09-12','2019-09-13','2019-09-14','2019-09-15','2019-09-21','2019-09-22','2019-09-28','2019-09-29',\n",
    "           '2019-10-03','2019-10-05','2019-10-06','2019-10-09','2019-10-12','2019-10-13','2019-10-19','2019-10-20',\n",
    "           '2019-10-26','2019-10-27']\n",
    "    trh11 = ['2018-12-01','2018-12-02','2018-12-08','2018-12-09','2018-12-15','2018-12-16',\n",
    "           '2018-12-22','2018-12-23','2018-12-25','2018-12-29','2018-12-30',\n",
    "           '2019-01-01','2019-01-05','2019-01-06','2019-01-12','2019-01-13','2019-01-19','2019-01-20','2019-01-26',\n",
    "           '2019-01-27','2019-02-02','2019-02-03','2019-02-04','2019-02-05','2019-02-06','2019-02-09','2019-02-10',\n",
    "           '2019-02-16','2019-02-17','2019-02-23','2019-02-24','2019-03-01','2019-03-02','2019-03-03','2019-03-09',\n",
    "           '2019-03-10','2019-03-16','2019-03-17','2019-03-23','2019-03-24','2019-03-30','2019-03-31','2019-04-06',\n",
    "           '2019-04-07','2019-04-13','2019-04-14','2019-04-20','2019-04-21','2019-04-27','2019-04-28','2019-05-04',\n",
    "           '2019-05-05','2019-05-06','2019-05-11','2019-05-12','2019-05-18','2019-05-19','2019-05-25','2019-05-26',\n",
    "           '2019-06-01','2019-06-02','2019-06-06','2019-06-08','2019-06-09','2019-06-15','2019-06-16','2019-06-22',\n",
    "           '2019-06-23','2019-06-29','2019-06-30','2019-07-06','2019-07-07','2019-07-13','2019-07-14','2019-07-20',\n",
    "           '2019-07-21','2019-07-27','2019-07-28','2019-08-03','2019-08-04','2019-08-10','2019-08-11','2019-08-15',\n",
    "           '2019-08-17','2019-08-18','2019-08-24','2019-08-25','2019-08-31','2019-09-01','2019-09-07','2019-09-08',\n",
    "           '2019-09-12','2019-09-13','2019-09-14','2019-09-15','2019-09-21','2019-09-22','2019-09-28','2019-09-29',\n",
    "           '2019-10-03','2019-10-05','2019-10-06','2019-10-09','2019-10-12','2019-10-13','2019-10-19','2019-10-20',\n",
    "           '2019-10-26','2019-10-27','2019-11-02','2019-11-03','2019-11-09','2019-11-10','2019-11-16','2019-11-17',\n",
    "           '2019-11-23','2019-11-24','2019-11-30']\n",
    "    trh12 = ['2019-01-01','2019-01-05','2019-01-06','2019-01-12','2019-01-13','2019-01-19','2019-01-20','2019-01-26',\n",
    "           '2019-01-27','2019-02-02','2019-02-03','2019-02-04','2019-02-05','2019-02-06','2019-02-09','2019-02-10',\n",
    "           '2019-02-16','2019-02-17','2019-02-23','2019-02-24','2019-03-01','2019-03-02','2019-03-03','2019-03-09',\n",
    "           '2019-03-10','2019-03-16','2019-03-17','2019-03-23','2019-03-24','2019-03-30','2019-03-31','2019-04-06',\n",
    "           '2019-04-07','2019-04-13','2019-04-14','2019-04-20','2019-04-21','2019-04-27','2019-04-28','2019-05-04',\n",
    "           '2019-05-05','2019-05-06','2019-05-11','2019-05-12','2019-05-18','2019-05-19','2019-05-25','2019-05-26',\n",
    "           '2019-06-01','2019-06-02','2019-06-06','2019-06-08','2019-06-09','2019-06-15','2019-06-16','2019-06-22',\n",
    "           '2019-06-23','2019-06-29','2019-06-30','2019-07-06','2019-07-07','2019-07-13','2019-07-14','2019-07-20',\n",
    "           '2019-07-21','2019-07-27','2019-07-28','2019-08-03','2019-08-04','2019-08-10','2019-08-11','2019-08-15',\n",
    "           '2019-08-17','2019-08-18','2019-08-24','2019-08-25','2019-08-31','2019-09-01','2019-09-07','2019-09-08',\n",
    "           '2019-09-12','2019-09-13','2019-09-14','2019-09-15','2019-09-21','2019-09-22','2019-09-28','2019-09-29',\n",
    "           '2019-10-03','2019-10-05','2019-10-06','2019-10-09','2019-10-12','2019-10-13','2019-10-19','2019-10-20',\n",
    "           '2019-10-26','2019-10-27','2019-11-02','2019-11-03','2019-11-09','2019-11-10','2019-11-16','2019-11-17',\n",
    "           '2019-11-23','2019-11-24','2019-11-30','2019-12-01','2019-12-07','2019-12-08','2019-12-14','2019-12-15',\n",
    "           '2019-12-21','2019-12-22','2019-12-25','2019-12-28','2019-12-29']\n",
    "    th1 = ['2019-02-02','2019-02-03','2019-02-04','2019-02-05','2019-02-06','2019-02-09','2019-02-10',\n",
    "           '2019-02-16','2019-02-17','2019-02-23','2019-02-24']\n",
    "    th2 = ['2019-03-01','2019-03-02','2019-03-03','2019-03-09',\n",
    "           '2019-03-10','2019-03-16','2019-03-17','2019-03-23','2019-03-24','2019-03-30','2019-03-31']\n",
    "    th3 = ['2019-04-06',\n",
    "           '2019-04-07','2019-04-13','2019-04-14','2019-04-20','2019-04-21','2019-04-27','2019-04-28']\n",
    "    th4 = ['2019-05-04',\n",
    "           '2019-05-05','2019-05-06','2019-05-11','2019-05-12','2019-05-18','2019-05-19','2019-05-25','2019-05-26']\n",
    "    th5 = ['2019-06-01','2019-06-02','2019-06-06','2019-06-08','2019-06-09','2019-06-15','2019-06-16','2019-06-22',\n",
    "           '2019-06-23','2019-06-29','2019-06-30']\n",
    "    th6 = ['2019-07-06','2019-07-07','2019-07-13','2019-07-14','2019-07-20',\n",
    "           '2019-07-21','2019-07-27','2019-07-28']\n",
    "    th7 = ['2019-08-03','2019-08-04','2019-08-10','2019-08-11','2019-08-15',\n",
    "           '2019-08-17','2019-08-18','2019-08-24','2019-08-25','2019-08-31']\n",
    "    th8 = ['2019-09-01','2019-09-07','2019-09-08',\n",
    "           '2019-09-12','2019-09-13','2019-09-14','2019-09-15','2019-09-21','2019-09-22','2019-09-28','2019-09-29']\n",
    "    th9 = ['2019-10-03','2019-10-05','2019-10-06','2019-10-09','2019-10-12','2019-10-13','2019-10-19','2019-10-20',\n",
    "           '2019-10-26','2019-10-27']\n",
    "    th10 = ['2019-11-02','2019-11-03','2019-11-09','2019-11-10','2019-11-16','2019-11-17',\n",
    "           '2019-11-23','2019-11-24','2019-11-30']\n",
    "    th11 = ['2019-12-01','2019-12-07','2019-12-08','2019-12-14','2019-12-15',\n",
    "           '2019-12-21','2019-12-22','2019-12-25','2019-12-28','2019-12-29']\n",
    "    th12 = ['2020-01-01','2020-01-04','2020-01-05','2020-01-11','2020-01-12','2020-01-18','2020-01-19','2020-01-24',\n",
    "           '2020-01-25','2020-01-26','2020-01-27']\n",
    "\n",
    "    train_holiday=[trh1,trh2,trh3,trh4,trh5,trh6,trh7,trh8,trh9,trh10,trh11,trh12]\n",
    "    test_holiday=[th1,th2,th3,th4,th5,th6,th7,th8,th9,th10,th11,th12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    for i in range(12):  # 총 12개의 train, test set\n",
    "\n",
    "        df_train=data.loc[start_date_train[i] : end_date_train[i], : ]\n",
    "        df_test=data.loc[start_date_test[i]: end_date_test[i], :]\n",
    "        df_train=df_train.reset_index()\n",
    "        df_test=df_test.reset_index()\n",
    "\n",
    "        # train scale 조정\n",
    "\n",
    "        y_original=np.array(df_train['y_original'])\n",
    "        sc=MinMaxScaler((0.05,0.95))\n",
    "        y=y_original.reshape(-1,1)\n",
    "        y = sc.fit_transform(y)\n",
    "        y_scale_train =pd.DataFrame(y)\n",
    "        y_scale_train.columns=['y']\n",
    "\n",
    "        df_train=pd.merge(df_train, y_scale_train[\"y\"], how='outer', left_index=True, right_index=True)\n",
    "        \n",
    "        # test scale 조정\n",
    "\n",
    "        y_scale_mean=df_train['y_original'].mean()\n",
    "        y_scale_std=df_train['y_original'].std()\n",
    "\n",
    "        df_test['y']=(df_test['y_original']-y_scale_mean)/y_scale_std\n",
    "\n",
    "        df_train=df_train.reset_index()\n",
    "        df_test=df_test.reset_index()\n",
    "\n",
    "        # 예측값의 상한과 하한을 제어\n",
    "        \n",
    "        df_train['cap'] = 1.0\n",
    "        df_train['floor'] = 0.0\n",
    "\n",
    "        # holiday이지만 주말과 공휴일을 다 삭제 \n",
    "        \n",
    "        holiday = pd.DataFrame({'holiday': 'holiday', 'ds': pd.to_datetime(train_holiday[i]), \n",
    "                'lower_window': 0, 'upper_window': 0})\n",
    "        m = Prophet(growth='logistic', holidays=holiday,yearly_seasonality=True, changepoint_range=0.9,\n",
    "                   interval_width=0.95,daily_seasonality=True) # 여기서 파라미터 추가, 삭제 \n",
    "        m.fit(df_train)\n",
    "\n",
    "        # 미래 Dataframe 생성\n",
    "        future = m.make_future_dataframe(periods=31)\n",
    "        future.head()\n",
    "\n",
    "        future=future.set_index('ds')\n",
    "        future_train=future.loc[start_date_train[i] : end_date_train[i], : ]\n",
    "        future_test=future.loc[start_date_test[i]: end_date_test[i], :]\n",
    "\n",
    "        future_train=future_train.reset_index()\n",
    "        future_test=future_test.reset_index()\n",
    "\n",
    "\n",
    "        start_date = datetime.strptime(start_date_test[i], '%Y-%m-%d') #시작 날짜\n",
    "        end_date = datetime.strptime(end_date_test[i], '%Y-%m-%d') #끝 날짜\n",
    "\n",
    "        test_total_date = [] \n",
    "\n",
    "        while start_date.strftime('%Y-%m-%d') != end_date.strftime('%Y-%m-%d'):\n",
    "            test_total_date.append(start_date.strftime('%Y-%m-%d')) \n",
    "            start_date += timedelta(days=1)\n",
    "\n",
    "\n",
    "        test_holiday_date=test_holiday[i]    #마찬가지로 주말, 공휴일 제거 추후 추가\n",
    "\n",
    "        final_date = list(set(test_total_date) - set(test_holiday_date))\n",
    "        future_test=future_test[future_test['ds'].isin(final_date)]\n",
    "        future=pd.concat([future_train,future_test],ignore_index=True)\n",
    "\n",
    "        future['cap'] = 1.0\n",
    "        future['floor'] = 0.0\n",
    "\n",
    "        # 예측하기\n",
    "\n",
    "        forecast = m.predict(future)  \n",
    "        #forecast.iloc[-(len(start_date_test[i]) + len(end_date_test[i])):, :].yhat.plot()\n",
    "        forecast=forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "\n",
    "        # 옵션 1. 예측한 상한, 하한 범위와 추세 방향을 그래프로 시각화\n",
    "        m.plot(forecast)\n",
    "        \n",
    "        # 옵션 2. 예측한 부분을 실제값과 그래프로 시각화\n",
    "        pred=forecast[-len(df_test):].reset_index()\n",
    "\n",
    "        plt.plot(pred['yhat'])\n",
    "        plt.plot(df_test['y'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5일간 상승, 하락 예상 -> 정확도 41.6%  \n",
    "\n",
    "| set01 | set02 | set03 | set04 |  set05 | set06 | set07 | set08 | set09 | set10 | set11 | set12 |   \n",
    "| -------- | ------- | -------- | -------- |  -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- |\n",
    "| 60% | 0% | 100% | 0% | 20% | 40% | 20% | 40% | 20% | 60% | 100% | 40% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음날 상승, 하락 예상 -> 정확도 25%\n",
    "\n",
    "| set01 | set02 | set03 | set04 |  set05 | set06 | set07 | set08 | set09 | set10 | set11 | set12 |   \n",
    "| -------- | ------- | -------- | -------- |  -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- |\n",
    "| X | X | O | X | X | X | X | X | X | O | O | X |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ARIMA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ARIMA모형은 시계열 데이터 기반 분석 기법으로 과거 지식이나 경험을 바탕으로 움직이고 있음을 기초로 한다. ARIMA모형은 과거의 관측 값과 오차를 현재의 시계열 값을 설명하는 ARMA모델에서 다소 비안정적인 시계열의 특징에 적용이 가능하도록 발전한 모델이다.\n",
    "\n",
    "- ARIMA를 이용하여 10개의 모델을 이용하여 예측한 결과 RMSE가 약 8~9원 정도가 나왔다. 모델을 구축하고 5일동안의 실제가격과 예측가격의 상승,하락만을 비교하였을때의 정확도는 대부분의 모델이 40% 정도의 성능을 보여주었다. prophet의 모델과 비교하였을때와 큰 차이는 없었지만, RMSE가 현저하게 줄었음을 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < 코드 > \n",
    "set01을 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    from statsmodels.tsa.arima_model import ARIMA\n",
    "    from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "    from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    data = pd.read_csv('exchange_data/set01.csv', header=0, squeeze=True)\n",
    "    data = data.set_index('Date')\n",
    "    \n",
    "    # 2018년 2월~2019년1월 train set/ 2019년 2월 test set\n",
    "    df_train=data.loc['2018-02-01': '2019-01-31' ]\n",
    "    df_test=data.loc['2019-02-01':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 구현 (최종 이용한 모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #model1\t\n",
    "\n",
    "    model_1 = ARIMA(df_train, order=(1,1,1))\n",
    "    model_1_fit = model_1.fit(trend='nc',full_output=True, disp=1)\n",
    "    print(model_1_fit.summary())\n",
    "\n",
    "    #model2\t\n",
    "\n",
    "    model_2 = ARIMA(df_train, order=(1,1,1))\n",
    "    model_2_fit = model_2.fit(trend='c',full_output=True, disp=1)\n",
    "    print(model_2_fit.summary())\n",
    "\n",
    "    #model3\t\n",
    "\n",
    "    model_3 = ARIMA(df_train, order=(2,1,1))\n",
    "    model_3_fit = model_3.fit(trend='c',full_output=True, disp=1)\n",
    "    print(model_3_fit.summary())\n",
    "\n",
    "    #model4\t\n",
    "\n",
    "    model_4 = ARIMA(df_train, order=(2,1,1))\n",
    "    model_4_fit = model_4.fit(trend='nc',full_output=True, disp=1)\n",
    "    print(model_4_fit.summary())\n",
    "\n",
    "    #model18\t\n",
    "\n",
    "    model_18 = ARIMA(df_train, order=(5,1,2))\n",
    "    model_18_fit = model_18.fit(trend='nc',full_output=True, disp=1)\n",
    "    print(model_18_fit.summary())\n",
    "\n",
    "    #model19\t\n",
    "\n",
    "    model_19 = ARIMA(df_train, order=(5,1,1))\n",
    "    model_19_fit = model_19.fit(trend='nc',full_output=True, disp=1)\n",
    "    print(model_19_fit.summary())\n",
    "\n",
    "    #model20\t\n",
    "\n",
    "    model_20 = ARIMA(df_train, order=(5,1,1))\n",
    "    model_20_fit = model_20.fit(trend='c',full_output=True, disp=1)\n",
    "    print(model_20_fit.summary())\n",
    "\n",
    "    #model25\t\n",
    "\n",
    "    model_25 = ARIMA(df_train, order=(5,0,0))\n",
    "    model_25_fit = model_25.fit(trend='c',full_output=True, disp=1)\n",
    "    print(model_25_fit.summary())\n",
    "\n",
    "    #model26\n",
    "\n",
    "    model_26 = ARIMA(df_train, order=(0,1,5))\n",
    "    model_26_fit = model_26.fit(trend='nc',full_output=True, disp=1)\n",
    "    print(model_26_fit.summary())\n",
    "\n",
    "    #model27\n",
    "\n",
    "    model_27 = ARIMA(df_train, order=(0,1,5))\n",
    "    model_27_fit = model_27.fit(trend='c',full_output=True, disp=1)\n",
    "    print(model_27_fit.summary())\n",
    "\n",
    "    #model28\n",
    "\n",
    "    model_28 = ARIMA(df_train, order=(0,1,4))\n",
    "    model_28_fit = model_28.fit(trend='nc',full_output=True, disp=1)\n",
    "    print(model_28_fit.summary())\n",
    "\n",
    "    #model29\n",
    "\n",
    "    model_29 = ARIMA(df_train, order=(0,1,4))\n",
    "    model_29_fit = model_29.fit(trend='c',full_output=True, disp=1)\n",
    "    print(model_29_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측후 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Models = [model_1_fit, model_2_fit, model_3_fit, model_4_fit, model_18_fit, model_19_fit, model_20_fit, \n",
    "              model_25_fit, model_26_fit, model_27_fit, model_28_fit, model_29_fit]\n",
    "\n",
    "    df_test=df_test[:5]\n",
    "    actual_price=df_test['Rate'].tolist()[:5]\n",
    "    RMSE_total=[]\n",
    "    pred_price=[]\n",
    "\n",
    "    for model in Models:\n",
    "        pred = model.forecast(steps=5)\n",
    "        pred_price_0=pred[0][:5]\n",
    "        pred_price.extend(pred_price_0)\n",
    "\n",
    "        plt.plot(pred_price_0)\n",
    "        plt.plot(df_test)\n",
    "        plt.show()\n",
    "\n",
    "        RMSE = mean_squared_error(pred_price_0, actual_price)**0.5    \n",
    "        RMSE_total.append(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prophet의 성능이 크게 좋지 않아서 추세만 확인하기 위해 arima모델을 사용함.    \n",
    "- 모델 자체의 구현이 간단한만큼 다양한 경우의 수를 생각하여 31개의 모델을 활용함.  \n",
    "- (0,0,0)~(5,1,5) 사이의 수를 활용하여 12개의 set에 모두 사용할수 있는 set은 12개.  \n",
    "- 이를 활용하여 실제값과 예측값이 다음날 맞을 확률, 5일 동안 추세가 맞을 확률을 구해봄.  \n",
    "- prophet보다는 좋은 성능을 보이지만, 여전히 50%를 넘지 못하는 한계가 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5일간 상승, 하락 예상 -> 12개의 모델 평균  \n",
    "  \n",
    "| model1 | model2 | model3 | model4 |  model18 | model19 | model20 | model25 | model26 | model27 | model28 | model29 |     \n",
    "| ---------- | :---------:| :----------: | ----------: |  ----------: | ----------: | ----------: | ----------: | ----------: | ----------: | ----------: | ----------: |  \n",
    "| 36.67% | 36.67% | 36.67% |\t33.33% |\t38.33% |\t40.00% |\t35.00% |\t40.00% |\t36.67% |\t33.33% |\t36.67% |\t35.00% |   \n",
    "  \n",
    "- 5일간 평균 RMSE  \n",
    "  \n",
    "| model1 | model2 | model3 | model4 |  model18 | model19 | model20 | model25 | model26 | model27 | model28 | model29 |   \n",
    "| ---------- | :---------:| :----------: | ----------: |  ----------: | ----------: | ----------: | ----------: | ----------: | ----------: | ----------: | ----------: |\n",
    "| 8.345  |  8.361 | 8.157  |  8.241 | 8.696  |  8.121 |  8.097 | 8.504  | 8.266  | 8.262  | 8.278  | 8.283  | \n",
    "  \n",
    "- 다음날 상승, 하락 예상 -> 정확도 평균\n",
    "  \n",
    "| model1 | model2 | model3 | model4 |  model18 | model19 | model20 | model25 | model26 | model27 | model28 | model29 |   \n",
    "| ---------- | :---------:| :----------: | ----------: |  ----------: | ----------: | ----------: | ----------: | ----------: | ----------: | ----------: | ----------: |\n",
    "| 42.67% | 42.67% | 50% | 33.33% | 42.67% | 42.67% | 50% | 50% | 42.67% | 33.33% | 50% | 33.33% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dnn 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DNN은 심층 신경망으로 입력층과 출력층 사이에 여러개의 은닉층으로 이뤄진 인공 신경망이다. dnn모델의 장점은 연속형, 범주형 변수를 모두 분석이 가능하며, 다른 머신러닝 기법에 비해 성능이 우수한 경우가 많다. 따라서 분류 및 수치예측을 위해 다양한 분야에서 dnn모델이 사용되어지고 있다.\n",
    "\n",
    "- dnn을 이용하여 다음날 환율의 가격과 상승, 하락을 예측하였다. 은닉층과 파라미터를 수정하며 다양하게 모델을 구성해 본 결과 RMSE는 10-11원 정도가 나왔다. 또한, 5일의 정확도는 80%로 나왔으며 총 11개월동안의 평균 정확도는 57~62% 정도의 성능을 보여주었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <  기본 코드 > "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, LSTM ,Dropout\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    from keras import layers\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    데이터 전처리\n",
    "    사용할 데이터 : 환율, 6개월 한국 미국 libor 금리, S&P 500, KOSPI200\n",
    "    \n",
    "    # 1. 환율\n",
    "    rate=pd.read_csv('data/set01.csv')\n",
    "    rate.columns=['date', 'rate']\n",
    "    rate=rate.set_index('date')\n",
    "    rate_train=rate.loc['2018-02-01': '2019-02-01' ]\n",
    "    rate_test=rate.loc['2019-02-01':'2019-03-01']\n",
    "    \n",
    "    # 2. 한국 libor\n",
    "    kolib=pd.read_csv('data/KORIBOR.csv')\n",
    "    kolib=kolib[['date', '6month']]\n",
    "    kolib.columns=['date','krlibor']\n",
    "    kolib=kolib.set_index('date')\n",
    "    kolib_train=kolib.loc['2018-02-01': '2019-01-31' ]\n",
    "    kolib_test=kolib.loc['2019-02-01':'2019-03-01']\n",
    "    \n",
    "    # 3. 미국 libor\n",
    "\n",
    "    uslib=pd.read_csv('data/libor.csv')\n",
    "    uslib.columns=['date','uslibor']\n",
    "    uslib=uslib.set_index('date')\n",
    "    uslib_train=uslib.loc['2018-02-01': '2019-01-31' ]\n",
    "    uslib_test=uslib.loc['2019-02-01':'2019-02-31']\n",
    "\n",
    "    # 데이터에 일부분에 . 이 존재함. \n",
    "    # 국가 공휴일은 삭제하고 필요한 값은 평균을 활용\n",
    "    del uslib_train['uslibor']['2018-12-25']\n",
    "    del uslib_train['uslibor']['2019-01-01']\n",
    "    uslib_train['uslibor'].loc['2018-03-30'] = (float(uslib_train['uslibor'].loc['2018-03-29']) * 2/3 \n",
    "                                                + float(uslib_train['uslibor'].loc['2018-04-03']) * 1/3)\n",
    "\n",
    "    uslib_train['uslibor'].loc['2018-04-02'] = (float(uslib_train['uslibor'].loc['2018-03-29']) * 1/3 \n",
    "                                                + float(uslib_train['uslibor'].loc['2018-04-03']) * 2/3)\n",
    "\n",
    "    uslib_train['uslibor'].loc['2018-05-07'] = (float(uslib_train['uslibor'].loc['2018-05-04']) * 1/2 \n",
    "                                                + float(uslib_train['uslibor'].loc['2018-05-08']) * 1/2)\n",
    "\n",
    "    uslib_train['uslibor'].loc['2018-05-28'] = (float(uslib_train['uslibor'].loc['2018-05-25']) * 1/2 \n",
    "                                                + float(uslib_train['uslibor'].loc['2018-05-29']) * 1/2)\n",
    "\n",
    "    uslib_train['uslibor'].loc['2018-08-27'] = (float(uslib_train['uslibor'].loc['2018-08-24']) * 1/2 \n",
    "                                                + float(uslib_train['uslibor'].loc['2018-08-28']) * 1/2)\n",
    "\n",
    "    uslib_train['uslibor'].loc['2018-12-26'] = (float(uslib_train['uslibor'].loc['2018-12-24']) * 2/3 \n",
    "                                                + float(uslib_train['uslibor'].loc['2018-12-27']) * 1/3)\n",
    "    # 값이 문자형으로 되어있어서 실수형으로 변경\n",
    "    uslib_train['uslibor']=uslib_train['uslibor'].apply(pd.to_numeric)\n",
    "    uslib_test['uslibor']=uslib_test['uslibor'].apply(pd.to_numeric)  \n",
    "    \n",
    "    # 4.s&p 500\n",
    "    snp500=pd.read_csv('data/S&P500.csv')\n",
    "    snp500 = snp500[::-1]\n",
    "    snp500=snp500[['날짜','종가']]\n",
    "    snp500.columns=['date','snp500']\n",
    "\n",
    "\n",
    "    snp500_date=[]\n",
    "    for i in snp500['date']:\n",
    "        snp500_date.append(i.replace('년 ','-').replace('월 ','-').replace('일',''))\n",
    "\n",
    "    snp500_price=[]\n",
    "    for i in snp500['snp500']:\n",
    "        i=i.replace(',','')\n",
    "        snp500_price.append(np.float(i))\n",
    "\n",
    "    snp500['date']=snp500_date\n",
    "    snp500['snp500']=snp500_price\n",
    "    snp500=snp500.set_index('date')\n",
    "\n",
    "    snp500_train = snp500.loc['2018-02-01': '2019-01-31' ]\n",
    "    snp500_test = snp500.loc['2018-02-01': '2019-02-31' ]\n",
    "    \n",
    "    # 5. kospi200\n",
    "    kospi200=pd.read_csv('data/KOSPI200.csv')\n",
    "    kospi200=kospi200[['날짜','종가']]\n",
    "    kospi200.columns=['date','kospi200']\n",
    "    kospi200 = kospi200[::-1]\n",
    "\n",
    "    kospi_date=[]\n",
    "    for i in kospi200['date']:\n",
    "        kospi_date.append(i.replace('년 ','-').replace('월 ','-').replace('일',''))\n",
    "\n",
    "    kospi200['date']=kospi_date\n",
    "    kospi200=kospi200.set_index('date')\n",
    "\n",
    "\n",
    "    kospi200_train = kospi200.loc['2018-02-01': '2019-01-31' ]\n",
    "    kospi200_test=kospi200.loc['2019-02-01':'2019-03-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정리한 데이터를 활용하여 같은 날로 묶어서 하나의 dataframe 생성 후 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    data_train=pd.concat([rate_train,kolib_train,uslib_train,snp500_train,kospi200_train], axis=1,  join = 'inner', sort=False)\n",
    "    data_test=pd.concat([rate_test,kolib_test,uslib_test,snp500_test,kospi200_test], axis=1,  join = 'inner', sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    data_train['y']=data_train['rate'].shift(-1)\n",
    "    data_test['y']=data_test['rate'].shift(-1)\n",
    "\n",
    "    #Nan 값을 계속 찾아서 업데이트 할 예정\n",
    "    data_train['y'][-1]=rate_test.iloc[0]\n",
    "    data_train=data_train[['krlibor','uslibor','snp500','kospi200','y']]\n",
    "\n",
    "    data_test['y'][-1]=rate_test.iloc[0]\n",
    "    data_test=data_test[['krlibor','uslibor','snp500','kospi200','y']]\n",
    "    data_test=data_test[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    train_input = data_train[['krlibor','uslibor','snp500','kospi200']]\n",
    "    train_target = data_train['y']\n",
    "    test_input = data_test[['krlibor','uslibor','snp500','kospi200']]\n",
    "    test_target = data_test['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scale맞추기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    mean = train_input.mean(axis=0)\n",
    "    std = train_input.std(axis=0)\n",
    "    train_input -= mean\n",
    "    train_input /= std\n",
    "    test_input -= mean\n",
    "    test_input /= std\n",
    "    In [22]:\n",
    "    train_input=np.array(train_input)\n",
    "    train_input=train_input.reshape(train_input.shape[0],4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구현하기 (DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    early_stopping = EarlyStopping(patience=50)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Dense(units=1024, input_shape=(4,)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(layers.Dense(units=128, input_shape=(4,)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    model.compile(optimizer='tanh', loss='mean_squared_error')\n",
    "    history = model.fit(train_input, train_target, epochs=1000, batch_size=32, validation_split=0.3, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss값 그래프로 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    y_vloss = history.history['val_loss']\n",
    "    y_loss = history.history['loss']\n",
    "\n",
    "    x_len = np.arange(len(y_loss))\n",
    "\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
    "    plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측하고 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    predicted = model.predict(test_input)\n",
    "    actual=data_test['y']\n",
    "\n",
    "    RMSE = mean_squared_error(actual, predicted)**0.5    \n",
    "    RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실제값 예측값 dataframe 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    predicted = sum(predicted.tolist(), [])\n",
    "    actual=actual.tolist()\n",
    "\n",
    "    final=pd.DataFrame([predicted, actual]).T\n",
    "    final.columns=['pred','actual']\n",
    "    final=final.set_index(data_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상승, 하락 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #train set의 마지막 데이터\n",
    "    lastday=rate_train[-1:]['rate']\n",
    "    In [ ]:\n",
    "    actual_updown=[]\n",
    "    pred_updown=[]\n",
    "    \n",
    "    if final['actual'][0] > lastday[0]:\n",
    "        actual_updown.append('up')\n",
    "    else :\n",
    "        actual_updown.appedn('down')\n",
    "\n",
    "    if final['pred'][0] > lastday[0]:\n",
    "        pred_updown.append('up')\n",
    "    else :\n",
    "        pred_updown.append('down')\n",
    "        \n",
    "    for i in range(len(final)-1):\n",
    "    \n",
    "        if final['actual'][i+1] > final['actual'][i]:\n",
    "            actual_updown.append('up')\n",
    "        else :\n",
    "            actual_updown.append('down')\n",
    "        \n",
    "    for i in range(len(final)-1):\n",
    "\n",
    "        if final['pred'][i+1] > final['actual'][i]:\n",
    "            pred_updown.append('up')\n",
    "        else :\n",
    "            pred_updown.append('down')\n",
    "            \n",
    "    final['pred_updown']=pred_updown\n",
    "    final['actual_updown']=actual_updown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # 한달간 예측\n",
    "    print('한달간 상승,하락 정확도 : ',round(sum(final['pred_updown'] == final['actual_updown'])/len(final)*100,2), '%')\n",
    "\n",
    "    # 5일만 예측\n",
    "    final_5=final[:5]\n",
    "    print('5일간 상승,하락 정확도 : ',round(sum(final_5['pred_updown'] == final_5['actual_updown'])/len(final_5)*100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그림으로 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    plt.plot(predicted, label='pred')\n",
    "    plt.plot(actual, label='actual')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set01만 활용하여 5일간 정확률 80%, RMSE=4.6으로 전체 11개(set01~set11)의 셋을 돌려봄.    \n",
    "- RMSE  \n",
    "    \n",
    "| set01 | set02 | set03 | set04 |  set05 | set06 | set07 | set08 | set09 | set10 | set11 |    \n",
    "| ---------- | :---------:| :----------: | ----------: |  ----------: | ----------: | ----------: | ----------: | ----------: | ----------: | ----------: |\n",
    "| 3.44 | 8.80 | 22.01 | 38.40 | 16.21 | 63.51 | 49.08 | 29.64 | 48.24 | 24.62 | 6.39 |  \n",
    "\n",
    "- 상승, 하락 예상(test set전체(한달), 5일, 다음날) -> 각각 확률 : 25%, 34.54%, 46.67%  \n",
    "    \n",
    "| 기준 | set01 | set02 | set03 | set04 |  set05 | set06 | set07 | set08 | set09 | set10 | set11 |     \n",
    "| ---------- | :---------:| :----------: | ----------: |  ----------: | ----------: | ----------: | ----------: | ----------: | ----------: | ----------: | ----------: |\n",
    "| 1일 | X | O | X | X | X | X | X | X | O | O | X |    \n",
    "| 5일 | 60.0  | 100.0  | 40.0  | 0.0  | 80.0  | 20.0  | 0.0  | 0.0 | 20.0  | 20.0  | 40.0  |  \n",
    "| 한달 | 40.0  | 78.95  | 30.0  | 15.79  | 77.78  | 38.1  | 35.0  | 47.06  | 35.0  | 52.63  | 63.16  |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파라미터를 수정하면서 모델 구현(위의 코드의 일부 변경)\n",
    "  \n",
    "|모델\t|\t1층(유닛,활성함수,dropout,규제)\t|\t2층(유닛,활성함수,dropout,규제)|\t3층(유닛,활성함수,dropout,규제)|\t\n",
    "| ---------- | :---------:| :----------: | ----------: |\n",
    "|1번 \t| \t1024, 0.1\t|\t128, 0.1 \t|X|\t\t\t\n",
    "|2번 \t| \t1024 relu, 0.1\t|1024 relu, 0.1  \t|X\t|\t\n",
    "|3번 \t| \t1024 relu, 0.2\t|1024 relu, 0.1\t\t|X\t|\n",
    "|4번 \t| \t1024, 0.1\t|\t1024, 0.2\t\t|1024,0.1 \t|\t\n",
    "|5번 \t| \t2048,0.2\t|\t1024, 0.2\t\t|512,0.2 \t \t|\n",
    "|6번 |\t\t512,0.2\t|\t512, 0.2\t|\t256,0.2  |\n",
    "|7번 \t|\t1024,0.1\t|\t512, 0.1\t|\t256,0.1 |\n",
    "|8번 |\t\t1024,512\t|\t256, 0.1 \t \t|X\t\t|\n",
    "|9번 \t|\t1024 softmax|\t512\t\t256,0.1  |X\t\t|\n",
    "|10번 |\t1024,0.2\t|\t512, 0.2\t|\t256,0.2, l1=0.01  |\n",
    "|11번 |\t1024,0.1\t|\t512, 0.1\t|\t245,0.1, l2=0.01  |\n",
    "|12번 |\t1024, 0.1\t|\t512, 0.1, l2=0.01 |X\t\t\t|\n",
    "|13번 |\t1024, 0.1\t|\t512, 0.1, l1=0.01\t \t|X\t|\n",
    "|14번 |\t1024,0.1\t|\t1024, 0.1  \t\t\t|X|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 기준 | model1 | model2 | model3 | model4 |  model5 | model6 | model7 | model8 | model9 | model10 | model11 | model12 | model13 | model14 |     \n",
    "| ---------- | :---------:| :----------: | ----------: |  ----------: | ----------: | ----------: | ----------: | ----------: | ----------: | ----------: | ----------: | ----------: | ----------: | ----------: |    \n",
    "| RMSE | 30.36 | 160.09 | 166.45 | 26.99 | 25.58 | 51.28 | 32.49 | 35.70 | 34.51 | 30.75 | 39.12 | 32.39 | 31.64 | 36.16 |    \n",
    "| 5일 | 36.36 | 45.45 | 27.27 | 40 | 50.09 | 45.45 | 40 | 45.45 | 47.27 | 41.81 | 29.09 | 36.36 | 34.54 | 36.36 |  \n",
    "| 한달 | 46.10 | 45.34 | 45.05 | 45.52 | 48.71 | 47.39 | 44.92 | 50.14 | 47.94 | 48.41 | 44.64 | 44.79 | 46.93 | 44.89 |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예측 결과\n",
    "\n",
    "- 은닉층을 1층만 쌓거나, 활성함수를 변경하면 오히려 값이 안좋게 나오는 경향이 있음. \n",
    "- 이를 통해 2층~3층 정도의 은닉층과 규제를 적절히 추가하는 법이 전체적으로 좋아지는 경향이 있음.\n",
    "- 업다운의 정확도 보다는 RMSE를 토대로 온라인 학습으로 그래프를 그려서 시각가 좋아 보임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 성능이 괜찮았던 모델들로 1년 train셋, 11개월 test셋으로 하여 모델을 돌려봄.\n",
    "\n",
    "| 모델 |\tRMSE |\t전체 |\t100일 |\t50일\t| 20일 |\t10일 |\t5일 |\n",
    "| ---------- | :---------:| :----------: | ----------: | ---------- | :---------:| :----------: | ----------: |\n",
    "|1-1번 |\t14.36\t|52.07%|\t50%|\t58%\t|70%|\t70%|\t80%|\n",
    "|1-2번\t| 11.08\t|58.99%\t|56%\t|66%\t|65%|\t60%\t|80%|\n",
    "|1-3번\t|11.03|\t59.99%|\t54%|\t62%|\t70%|\t60%|\t80%|\n",
    "|4-1번|\t33.23\t|45.16%|\t39%|\t38%|\t35%|\t40%|\t20%|\n",
    "|5-1번|\t23.12\t|51.15%\t|51%|\t62%\t|70%|\t60%\t|60%|\n",
    "|8-1번\t|10.74\t|57.6%|\t53%\t|64%|\t75%\t|70%|\t80%|\n",
    "|8-2번|\t10.69\t|57.6%|\t50%|\t60%\t|60%\t|60%|\t80%|\n",
    "|8-3번|\t10.8\t|61.29%\t|56%|\t66%\t|65%|\t60%\t|80%|\n",
    "|10번|\t39.39\t|45.16%\t|39%|\t38%\t|35%|\t40%\t|20%|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
